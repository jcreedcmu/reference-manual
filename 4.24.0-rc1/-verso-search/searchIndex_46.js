window.docContents[46].resolve({"/Definitions/Recursive-Definitions/#recursive-definitions":{"contents":"Allowing arbitrary recursive function definitions would make Lean's logic inconsistent.\nGeneral recursion makes it possible to write circular proofs: \"proposition P is true because proposition P is true\".\nOutside of proofs, an infinite loop could be assigned the type Empty, which can be used with nomatch or Empty.rec to prove any theorem.\n\nBanning recursive function definitions outright would render Lean far less useful: inductive types are key to defining both predicates and data, and they have a recursive structure.\nFurthermore, most useful recursive functions do not threaten soundness, and infinite loops usually indicate mistakes in definitions rather than intentional behavior.\nInstead of banning recursive functions, Lean requires that each recursive function is defined safely.\nWhile elaborating recursive definitions, the Lean elaborator also produces a justification that the function being defined is safe.The section on the elaborator's output in the overview of elaboration contextualizes the elaboration of recursive definitions in the overall context of the elaborator.\n\nThere are five main kinds of recursive functions that can be defined:\n\n Structurally recursive functions\n\nStructurally recursive functions take an argument such that the function makes recursive calls only on strict sub-components of said argument.Strictly speaking, arguments whose types are indexed families are grouped together with their indices, with the whole collection considered as a unit.\n  The elaborator translates the recursion into uses of the argument's recursor.\n  Because every type-correct use of a recursor is guaranteed to avoid infinite regress, this translation is evidence that the function terminates.\n  Applications of functions defined via recursors are definitionally equal to the result of the recursion, and are typically relatively efficient inside the kernel.\n\n Recursion over well-founded relations\n\nMany functions are also difficult to convert to structural recursion; for instance, a function may terminate because the difference between an array index and the size of the array decreases as the index increases, but Nat.rec isn't applicable because the index that increases is the function's argument.\n  Here, there is a measure of termination that decreases at each recursive call, but the measure is not itself an argument to the function.\n  In these cases, well-founded recursion can be used to define the function.\n  Well-founded recursion is a technique for systematically transforming recursive functions with a decreasing measure into recursive functions over proofs that every sequence of reductions to the measure eventually terminates at a minimum.\n  Applications of functions defined via well-founded recursion are not necessarily definitionally equal to their return values, but this equality can be proved as a proposition.\n  Even when definitional equalities exist, these functions are frequently slow to compute with because they require reducing proof terms that are often very large.\n\n Recursive functions as partial fixpoints\n\nThe definition of a function can be understood as an equation that specifies its behavior.\n  In certain cases, the existence of a function that satisfies this specification can be proven even when the recursive function does not necessarily terminate for all inputs.\n  This strategy is even applicable in some cases where the function definition does not necessarily terminate for all inputs.\n  These partial functions emerge as fixed points of these equations are called partial fixpoints.In particular, any function whose return type is in certain monads (e.g. Option) can be defined using this strategy.\n  Lean generates additional partial correctness theorems for these monadic functions.\n  As with well-founded recursion, applications of functions defined as partial fixpoints are not definitionally equal to their return values, but Lean generates theorems that propositionally equate the function to its unfolding and to the reduction behavior specified in its definition.\n\n Partial functions with nonempty codomains\n\nFor many applications, it's not important to reason about the implementation of certain functions.\n  A recursive function might be used only as part of the implementation of proof automation steps, or it might be an ordinary program that will never be formally proved correct.\n  In these cases, the Lean kernel does not need either definitional or propositional equalities to hold for the definition; it suffices that soundness is maintained.\n  Functions marked partial are treated as opaque constants by the kernel and are neither unfolded nor reduced.\n  All that is required for soundness is that their return type is inhabited.\n  Partial functions may still be used in compiled code as usual, and they may appear in propositions and proofs; their equational theory in Lean's logic is simply very weak.\n\n Unsafe recursive definitions\n\nUnsafe definitions have none of the restrictions of partial definitions.\n  They may freely make use of general recursion, and they may use features of Lean that break assumptions about its equational theory, such as primitives for casting (unsafeCast), checking pointer equality (ptrAddrUnsafe), and observing reference counts (isExclusiveUnsafe).\n  However, any declaration that refers to an unsafe definition must itself be marked unsafe, making it clear when logical soundness is not guaranteed.\n  Unsafe operations can be used to replace the implementations of other functions with more efficient variants in compiled code, while the kernel still uses the original definition.\n  The replaced function may be opaque, which results in the function name having a trivial equational theory in the logic, or it may be an ordinary function, in which case the function is used in the logic.\n  Use this feature with care: logical soundness is not at risk, but the behavior of programs written in Lean may diverge from their verified logical models if the unsafe implementation is incorrect.\n\n\n\n\n\nAs described in the overview of the elaborator's output, elaboration of recursive functions proceeds in two phases:\n\n1. The definition is elaborated as if Lean's core type theory had recursive definitions.\n    Aside from using recursion, this provisional definition is fully elaborated.\n    The compiler generates code from these provisional definitions.2. A termination analysis attempts to use the four techniques to justify the function to Lean's kernel.\n    If the definition is marked unsafe or partial, then that technique is used.\n    If an explicit termination_by clause is present, then the indicated technique is the only one attempted.\n    If there is no such clause, then the elaborator performs a search, testing each parameter to the function as a candidate for structural recursion, and attempting to find a measure with a well-founded relation that decreases at each recursive call.\n\nThis section describes the rules that govern recursive functions.\nAfter a description of mutual recursion, each of the five kinds of recursive definitions is specified, along with the tradeoffs between reasoning power and flexibility that go along with each.\n\n\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Definitions","header":"7.6. Recursive Definitions","id":"/Definitions/Recursive-Definitions/#recursive-definitions"},"/Functors___-Monads-and--do--Notation/Syntax/#The-Lean-Language-Reference--Functors___-Monads-and--do--Notation--Syntax--do--Notation--Sequential-Computations":{"contents":"One form of do item is a term.\n\nTerms in do-Notation\n\nA term followed by a sequence of items is translated to a use of bind; in particular, do e1; es is translated to e1 >>= fun () => do es.\n\n* do Item* Desugaring\n* do\ne1\nes\n* e1 >>= fun () => do es\n\n\n\n\nThe result of the term's computation may also be named, allowing it to be used in subsequent steps.\nThis is done using let.\n\n\n\nData Dependence in do-NotationThere are two forms of monadic let-binding in a do block.\nThe first binds an identifier to the result, with an optional type annotation:The second binds a pattern to the result.\nThe fallback clause, beginning with |, specifies the behavior when the pattern does not match the result.\n\nThis syntax is also translated to a use of bind.\ndo let x ← e1; es is translated to e1 >>= fun x => do es, and fallback clauses are translated to default pattern matches.\nlet may also be used with the standard definition syntax := instead of ←.\nThis indicates a pure, rather than monadic, definition:\n\nLocal Definitions in do-Notation\n\ndo let x := e; es is translated to let x := e; do es.\n\n* do Item* Desugaring\n* do\nlet x ← e1\nes\n* e1 >>= fun x =>\n  do es\n* do\nlet some x ← e1?\n  | fallback\nes\n* e1? >>= fun\n  | some x => do\n    es\n  | _ => fallback\n* do\nlet x := e\nes\n* let x := e\ndo es\n\n\n\n\nWithin a do block, ← may be used as a prefix operator.\nThe expression to which it is applied is replaced with a fresh variable, which is bound using bind just before the current step.\nThis allows monadic effects to be used in positions that otherwise might expect a pure value, while still maintaining the distinction between describing an effectful computation and actually executing its effects.\nMultiple occurrences of ← are processed from left to right, inside to outside.\n\nExample Nested Action Desugarings* Example do Item* Desugaring\n* do\nf (← e1) (← e2)\nes\n* do\nlet x ← e1\nlet y ← e2\nf x y\nes\n* do\nlet x := g (← h (← e1))\nes\n* do\nlet y ← e1\nlet z ← h y\nlet x := g z\nes\n\n\n\n\nIn addition to convenient support for sequential computations with data dependencies, do-notation also supports the local addition of a variety of effects, including early return, local mutable state, and loops with early termination.\nThese effects are implemented via transformations of the entire do block in a manner akin to monad transformers, rather than via a local desugaring.\n\n","context":"Lean Reference\u0009Functors, Monads and  do -Notation\u0009Syntax\u0009do -Notation","header":"14.3.2.1. Sequential Computations","id":"/Functors___-Monads-and--do--Notation/Syntax/#The-Lean-Language-Reference--Functors___-Monads-and--do--Notation--Syntax--do--Notation--Sequential-Computations"},"/releases/v4.18.0/#release-v4___18___0":{"contents":"For this release, 344 changes landed. In addition to the 166 feature additions and 38 fixes listed below there were 13 refactoring changes, 10 documentation improvements, 3 performance improvements, 4 improvements to the test suite and 109 other changes.HighlightsLean v4.18 release brings a number of exciting new features:* Inlay hints for auto implicitsThe Language Server now uses inlay hints to show which variables are brought into scope implicitly, and where. The hint\nreveals its type upon hover, and double-clicking the hint will insert the variable binding explicitly.See the description of #6768 for a screenshort.Note that this feature is only visible when set_option autoImplicit true, which is the default in plain Lean projects,\nbut not in mathlib* #6935 adds the tactic expose_names. It creates a new goal whose\nlocal context has been \"exposed\" so that every local declaration has a\nclear, accessible name. If no local declarations require renaming, the\noriginal goal is returned unchanged./--\ninfo: α : Sort u_1\na b : α\nh_1 : a = b\nh_2 : True\nh_3 : True ∨ False\nh : b = a\n⊢ b = a\n-/\n#guard_msgs (info) in\nexample (a b : α) (h : a = b) (_ : True) (_ : True ∨ False) (h : b = a) : b = a := by\n  expose_names\n  trace_state\n  rw [h]\nThis tactic intended for use in auto-generated tactic suggestions, and can also be useful\nduring proof exploration. It is still best practice to name variables where they are\nbrought into scope (intro, case etc.), and not use expose_names in a finished,\npolished proof.* #7069 adds the fun_induction and fun_cases tactics, which add\nconvenience around using functional induction and functional cases\nprinciples.fun_induction foo  x y z\nelaborates foo x y z, then looks up foo.induct, and then essentially doesinduction z using foo.induct y\nincluding and in particular figuring out which arguments are parameters,\ntargets or dropped. This only works for non-mutual functions so far.Likewise there is the fun_cases tactic using foo.fun_cases.* #6744 extend the preprocessing of well-founded recursive definitions\nto bring assumptions like h✝ : x ∈ xs, if a recursive call is in the\nargument of a higher-order function like List.map, into scope automatically.\nIn many cases this removes the need to use functions like List.attach.This feature can be disabled with set_option wf.preprocess false.* #6634 adds support for changing the binder annotations of existing\nvariables to and from strict-implicit and instance-implicit using the\nvariable command.* #7100 modifies the structure syntax so that parents can be named,\nlike instructure S extends toParent : P\nBreaking change: The syntax is also modified so that the resultant\ntype comes before the extends clause, for example structure S : Prop extends P. This is necessary to prevent a parsing ambiguity, but\nalso this is the natural place for the resultant type. Implements RFC\n#7099.* #7103 gives the induction tactic the ability to name hypotheses to\nuse when generalizing targets, just like in cases. For example,\ninduction h : xs.length leads to goals with hypotheses h : xs.length = 0 and h : xs.length = n + 1. Target handling is also slightly\nmodified for multi-target induction principles: it used to be that if\nany target was not a free variable, all of the targets would be\ngeneralized (thus causing free variables to lose their connection to the\nlocal hypotheses they appear in); now only the non-free-variable targets\nare generalized.* #6869 adds a recommended_spelling command, which can be used for\nrecording the recommended spelling of a notation (for example, that the\nrecommended spelling of ∧ in identifiers is and). This information\nis then appended to the relevant docstrings for easy lookup.* #6893 adds support for plugins to the frontend and server.* #7061 provides a basic API for a premise selection tool, which can be\nprovided in downstream libraries. It does not implement premise\nselection itself!And many more! Check out the Language section below.Notably, a line of work has been carried out on the following\n(see the corresponding subsections in the Language section for the details):* the try? tactic, which has been re-implemented using evalAndSuggest tactic.\ntry? now supports referencing inaccessible local names and can provide\nmore complex suggestions, involving exact? and fun_induction tactics.\nNew configuration options have been added: -only, +missing, and max:=<num>,\nas well as merge.* bv_decide tactic. There are new features in preprocessing, added support\nfor enum inductives, IntX and ISize, and improved performance in LRAT trimming.* normalization for linear integer arithmetic expressions has been implemented\nand connected to simp +arith. #7043 deprecates the tactics simp_arith,\nsimp_arith!, simp_all_arith and simp_all_arith! in favor of simp +arith.Important Library updates include:* #6914 introduces ordered map data structures, namely DTreeMap,\nTreeMap, TreeSet and their .Raw variants, into the standard\nlibrary.  A collection of lemmas about the operations on these data structures has\nbeen added in the subsequent PRs.* #7255 fixes the definition of Min (Option α). This is a breaking\nchange. This treats none as the least element,\nso min none x = min x none = none for all x : Option α. Prior to\nnightly-2025-02-27, we instead had min none (some x) = min (some x) none = some x. Also adds basic lemmas relating min, max, ≤ and\n< on Option.Significant development has been made in the verification APIs of BitVec\nand fixed-width integer types (IntX), along with ongoing work to align\nList/Array/Vector APIs. Several lemmas about Int.ediv/fdiv/tdiv have\nbeen strengthened.#6950 adds a style guide and a naming convention for the standard library.This summary of highlights was contributed by Violetta Sim.Language* #6634 adds support for changing the binder annotations of existing\nvariables to and from strict-implicit and instance-implicit using the\nvariable command.* #6744 extends the preprocessing of well-founded recursive definitions,\nsee the highlights section for details.* #6823 adds a builtin tactic and a builtin attribute that are required\nfor the tree map. The tactic, as_aux_lemma, can generally be used to\nwrap the proof term generated by a tactic sequence into a separate\nauxiliary lemma in order to keep the proof term small. This can, in rare\ncases, be necessary if the proof term will appear multiple times in the\nencompassing term. The new attribute, Std.Internal.tree_tac, is\ninternal and should not be used outside of Std.* #6853 adds support for anonymous equality proofs in match\nexpressions of the form match _ : e with ....* #6869 adds a recommended_spelling command; see the highlights\nsection for details.* #6891 modifies rewrite/rw to abort rewriting if the elaborated\nlemma has any immediate elaboration errors (detected by presence of\nsynthetic sorries). Rewriting still proceeds if there are elaboration\nissues arising from pending synthetic metavariables, like instance\nsynthesis failures. The purpose of the change is to avoid obscure\n\"tactic 'rewrite' failed, equality or iff proof expected ?m.5\" errors\nwhen for example a lemma does not exist.* #6893 adds support for plugins to the frontend and server.* #6935 adds the tactic expose_names; see the highlights section\nfor details.* #6936 fixes the #discr_tree_simp_key command, because it displays\nthe keys for just lhs in lhs ≠ rhs, but it should be lhs = rhs,\nsince that is what simp indexes.* #6939 adds error messages for inductive declarations with\nconflicting constructor names and mutual declarations with conflicting\nnames.* #6947 adds the binderNameHint gadget. It can be used in rewrite and\nsimp rules to preserve a user-provided name where possible.The expression binderNameHint v binder e defined to be e.If it is used on the right-hand side of an equation that is applied by\na tactic like rw or simp, and v is a local variable, and binder\nis an expression that (after beta-reduction) is a binder (so fun w => … or ∀ w, …),\nthen it will rename v to the name used in the binder, and remove the binderNameHint.A typical use of this gadget would be as follows; the gadget ensures\nthat after rewriting, the local variable is still name, and not x:theorem all_eq_not_any_not (l : List α) (p : α → Bool) :\n    l.all p = !l.any fun x => binderNameHint x p (!p x) := sorry\n\nexample (names : List String) : names.all (fun name => \"Waldo\".isPrefixOf name) = true := by\n  rw [all_eq_not_any_not]\n  -- ⊢ (!names.any fun name => !\"Waldo\".isPrefixOf name) = true\nThis gadget is supported by simp, dsimp and rw in the right-hand-side\nof an equation, but not in hypotheses or by other tactics.* #6951 adds line breaks and indentations to simp's trace messages to\nmake them easier to read (IMHO).* #6964 adds a convenience command #info_trees in, which prints the\ninfo trees generated by the following command. It is useful for\ndebugging or learning about InfoTree.* #7039 improves the well-founded definition preprocessing to propagate\nwfParam through let expressions.* #7053 makes simp heed the binderNameHint also in the assumptions\nof congruence rules. Fixes #7052.* #7055 improves array and vector literal syntax by allowing trailing\ncommas. For example, #[1, 2, 3,].* #7061 provides a basic API for a premise selection tool; see the\nhighlights section for details.* #7078 implements simprocs for Int and Nat divides predicates.* #7088 fixes the behavior of the indexed-access notation xs[i] in\ncases where the proof of i's validity is filled in during unification.* #7090 strips lib prefixes and _shared suffixes from plugin names.\nIt also moves most of the dynlib processing code to Lean to make such\npreprocessing more standard.* #7100 modifies the structure syntax; see the highlights section for details.* #7103 gives the induction tactic the ability to name hypotheses; see\nthe highlights section for details.* #7119 makes linter names clickable in the trace.profiler output.* #7191 fixes the indentation of \"Try this\" suggestions in widget-less\nmultiline messages, as they appear in #guard_msgs outputs.* #7192 prevents exact? and apply? from suggesting tactics that\ncorrespond to correct proofs but do not elaborate, and it allows these\ntactics to suggest expose_names when needed.* #7200 allows the debug form of DiscrTree.Key to line-wrap.* #7213 adds SetConsoleOutputCP(CP_UTF8) during runtime initialization\nto properly display Unicode on the Windows console. This effects both\nthe Lean executable itself and user executables (including Lake).* #7224 make induction … using and cases … using complain if more\ntargets were given than expected by that eliminator.* #7294 fixes bugs in Std.Internal.Rat.floor and\nStd.Internal.Rat.ceil.Updates to the try? Tactic* #6961 adds the auxiliary tactic evalAndSuggest. It will be used to\nrefactor try?.* #6965 re-implements the try? tactic using the new evalAndSuggest\ninfrastructure.* #6967 ensures try? can suggest tactics that need to reference\ninaccessible local names.\nExample:/--\ninfo: Try these:\n• · expose_names; induction as, bs_1 using app.induct <;> grind [= app]\n• · expose_names; induction as, bs_1 using app.induct <;> grind only [app]\n-/\n#guard_msgs (info) in\nexample : app (app as bs) cs = app as (app bs cs) := by\n  have bs := 20 -- shadows `bs` in the target\n  try?\n* #6979 adds support for more complex suggestions in try?.\nExample:example (as : List α) (a : α) : concat as a = as ++ [a] := by\n  try?\nsuggestionTry this: · induction as, a using concat.induct\n  · rfl\n  · simp_all\n* #6980 improves the try? tactic runtime validation and error\nmessages. It also simplifies the implementation, and removes unnecessary\ncode.* #6981 adds new configuration options to try?.* try? -only omits simp only and grind only suggestions* try? +missing enables partial solutions where some subgoals are\n\"solved\" using sorry, and must be manually proved by the user.* try? (max:=<num>) sets the maximum number of suggestions produced\n(default is 8).* #6991 improves how suggestions for the <;> combinator are generated.* #6994 adds the Try.Config.merge flag (true by default) to the\ntry? tactic. When set to true, try? compresses suggestions such\nas:· induction xs, ys using bla.induct\n    · grind only [List.length_reverse]\n    · grind only [bla]\ninto:induction xs, ys using bla.induct <;> grind only [List.length_reverse, bla]\n* #6995 implements support for exact? in the try? tactic.* #7082 makes try? use fun_induction instead of induction … using foo.induct. It uses the argument-free short-hand fun_induction foo if\nthat is unambiguous. Avoids expose_names if not necessary by simply\ntrying without first.Functional Induction Tactic* #7069 adds the fun_induction and fun_cases tactics, which add\nconvenience around using functional induction and functional cases\nprinciples.* #7101 implements fun_induction foo, which is like fun_induction foo x y z, only that it picks the arguments to use from a unique suitable\ncall to foo in the goal.* #7127 follows up on #7103 which changes the generaliziation behavior\nof induction, to keep fun_induction in sync. Also fixes a Syntax\nindexing off-by-one error.bv_decide Tactic* #6741 implements two rules for bv_decide's preprocessor, lowering\n||| to &&& in order to enable more term sharing + application of\nrules about &&& as well as rewrites of the form (a &&& b == -1#w) = (a == -1#w && b == -1#w) in order to preserve rewriting behavior that\nalready existed before this lowering.* #6924 adds the EQUAL_ITE rules from Bitwuzla to the preprocessor of\nbv_decide.* #6926 adds the BV_EQUAL_CONST_NOT rules from Bitwuzla to the\npreprocessor of bv_decide.* #6946 implements basic support for handling of enum inductives in\nbv_decide. It now supports equality on enum inductive variables (or\nother uninterpreted atoms) and constants.* #7009 ensures users get an error message saying which module to import\nwhen they try to use bv_decide.* #7019 properly spells out the trace nodes in bv_decide so they are\nvisible with just trace.Meta.Tactic.bv and trace.Meta.Tactic.sat\ninstead of always having to enable the profiler.* #7021 adds theorems for interactions of extractLsb with &&&, ^^^,\n~~~ and bif to bv_decide's preprocessor.* #7029 adds simprocs to bv_decide's preprocessor that rewrite\nmultiplication with powers of two to constant shifts.* #7033 improves presentation of counter examples for UIntX and enum\ninductives in bv_decide.* #7242 makes sure bv_decide can work with projections applied to ite\nand cond in its structures pass.* #7257 improves performance of LRAT trimming in bv_decide.* #7269 implements support for IntX and ISize in bv_decide.* #7275 adds all level 1 rewrites from Bitwuzla to the preprocessor of\nbv_decide.Parallelizing Elaboration* #6770 enables code generation to proceed in parallel to further\nelaboration.* #6988 ensures interrupting the kernel does not lead to wrong, sticky\nerror messages in the editor* #7047 removes the save and checkpoint tactics that have been\nsuperseded by incremental elaboration* #7076 introduces the central parallelism API for ensuring that helper\ndeclarations can be generated lazily without duplicating work or\ncreating conflicts across threads.Linear Integer Normalization in simp +arith* #7000 adds helper theorems for justifying the linear integer\nnormalizer.* #7002 implements the normalizer for linear integer arithmetic\nexpressions. It is not connect to simp +arith yet because of some\nspurious [simp] attributes.* #7011 adds simp +arith for integers. It uses the new grind\nnormalizer for linear integer arithmetic. We still need to implement\nsupport for dividing the coefficients by their GCD. It also fixes\nseveral bugs in the normalizer.* #7015 makes sure simp +arith normalizes coefficients in linear\ninteger polynomials. There is still one todo: tightening the bound of\ninequalities.* #7030 adds completes the linear integer inequality normalizer for\ngrind. The missing normalization step replaces a linear inequality of\nthe form a_1*x_1 + ... + a_n*x_n + b <= 0 with a_1/k * x_1 + ... + a_n/k * x_n + ceil(b/k) <= 0 where k = gcd(a_1, ..., a_n).\nceil(b/k) is implemented using the helper cdiv b k.* #7040 ensures that terms such as f (2*x + y) and f (y + x + x)\nhave the same normal form when using simp +arith* #7043 deprecates the tactics simp_arith, simp_arith!,\nsimp_all_arith and simp_all_arith!. Users can just use the +arith\noption.grind TacticThe grind tactic is still is experimental and still under development. Avoid using it in production projects* #6902 ensures simp diagnostic information in included in the grind\ndiagnostic message.* #6937 improves grind error and trace messages by cleaning up local\ndeclaration names.* #6940 improves how the grind tactic performs case splits on p <-> q.* #7102 modifies grind to run with the reducible transparency\nsetting. We do not want grind to unfold arbitrary terms during\ndefinitional equality tests. also fixes several issues\nintroduced by this change. The most common problem was the lack of a\nhint in proofs, particularly in those constructed using proof by\nreflection. also introduces new sanity checks when set_option grind.debug true is used.* #7231 implements functions for constructing disequality proofs in\ngrind.Cutsat Procedure (Solver for Linear Integer Arithmetic Problems)* #7077 proves the helper theorems for justifying the \"Div-Solve\" rule\nin the cutsat procedure.* #7091 adds helper theorems for normalizing divisibility constraints.\nThey are going to be used to implement the cutsat procedure in the\ngrind tactic.* #7092 implements divisibility constraint normalization in simp +arith.* #7097 implements several modifications for the cutsat procedure in\ngrind.* The maximal variable is now at the beginning of linear polynomials.* The old LinearArith.Solver was deleted, and the normalizer was moved\nto Simp.* cutsat first files were created, and basic infrastructure for\nrepresenting divisibility constraints was added.* #7122 implements the divisibility constraint solver for the cutsat\nprocedure in the grind tactic.* #7124 adds the helper theorems for justifying the divisibility\nconstraint solver in the cutsat procedure used by the grind tactic.* #7138 implements proof generation for the divisibility constraint\nsolver in grind.* #7139 uses a let-expression for storing the (shared) context in\nproofs produced by the cutsat procedure in grind.* #7152 implements the infrastructure for supporting integer inequality\nconstraints in the cutsat procedure.* #7155 implements some infrastructure for the model search procedure in\ncutsat.* #7156 adds a helper theorem that will be used in divisibility\nconstraint conflict resolution during model construction.* #7176 implements model construction for divisibility constraints in\nthe cutsat procedure.* #7183 improves the cutsat model search procedure.* #7186 simplifies the proofs and data structures used by cutsat.* #7193 adds basic infrastructure for adding support for equalities in\ncutsat.* #7194 adds support theorems for solving equality in cutsat.* #7202 adds support for internalizing terms relevant to the cutsat\nmodule. This is required to implement equality propagation.* #7203 improves the support for equalities in cutsat. It also\nsimplifies a few support theorems used to justify cutsat rules.* #7217 improves the support for equalities in cutsat.* #7220 implements the missing cases for equality propagation from the\ngrind core to the cutsat module.* #7234 implements dIsequality propagation from grind core module to\ncutsat.* #7244 adds support for disequalities in the cutsat procedure used in\ngrind.* #7248 implements simple equality propagation in cutsat p <= 0 -> -p <= 0 -> p = 0* #7252 implements inequality refinement using disequalities. It\nminimizes the number of case splits cutsat will have to perform.* #7267 improves the cutsat search procedure. It adds support for find\nan approximate rational solution, checks disequalities, and adds stubs\nfor all missing cases.* #7278 adds counterexamples for linear integer constraints in the\ngrind tactic. This feature is implemented in the cutsat procedure.* #7279 adds support theorems for the Cooper-Dvd-Left conflict\nresolution rule used in the cutsat procedure. During model construction,\nwhen attempting to extend the model to a variable x, cutsat may find a\nconflict that involves two inequalities (the lower and upper bounds for\nx) and a divisibility constraint:a * x + p ≤ 0\nb * x + q ≤ 0\nd ∣ c * x + s\n* #7284 implements non-choronological backtracking for the cutsat\nprocedure. The procedure has two main kinds of case-splits:\ndisequalities and Cooper resolvents. focus on the first kind.* #7290 adds support theorems for the Cooper-Left conflict\nresolution rule used in the cutsat procedure. During model\nconstruction,when attempting to extend the model to a variable x,\ncutsat may find a conflict that involves two inequalities (the lower and\nupper bounds for x). This is a special case of Cooper-Dvd-Left when\nthere is no divisibility constraint.* #7292 adds support theorems for the Cooper-Dvd-Right conflict\nresolution rule used in the cutsat procedure. During model construction,\nwhen attempting to extend the model to a variable x, cutsat may find a\nconflict that involves two inequalities (the lower and upper bounds for\nx) and a divisibility constraint.* #7293 adds support theorems for the Cooper-Right conflict resolution\nrule used in the cutsat procedure. During model construction, when\nattempting to extend the model to a variable x, cutsat may find a\nconflict that involves two inequalities (the lower and upper bounds for\nx). This is a special case of Cooper-Dvd-Right when there is no\ndivisibility constraint.* #7409 allows the use of dsimp during preprocessing of well-founded\ndefinitions. This fixes regressions when using if-then-else without\ngiving a name to the condition, but where the condition is needed for\nthe termination proof, in cases where that subexpression is reachable\nonly by dsimp, but not by simp (e.g. inside a dependent let)Library* #5498 makes BitVec.getElem the simp normal form in case a proof is\navailable and changes ext to return x[i] + a hypothesis that proves\nthat we are in-bounds. This aligns BitVec further with the API\nconventions of the Lean standard datatypes.* #6326 adds BitVec.(getMsbD, msb)_replicate, replicate_one theorems,\ncorrects a non-terminal simp in BitVec.getLsbD_replicate and\nsimplifies the proof of BitVec.getElem_replicate using the cases\ntactic.* #6628 adds SMT-LIB operators to detect overflow\nBitVec.(uadd_overflow, sadd_overflow), according to the definitions\nhere,\nand the theorems proving equivalence of such definitions with the\nBitVec library functions (uaddOverflow_eq, saddOverflow_eq).\nSupport theorems for these proofs are BitVec.toNat_mod_cancel_of_lt, BitVec.toInt_lt, BitVec.le_toInt, Int.bmod_neg_iff. The PR also\nincludes a set of tests.* #6792 adds theorems BitVec.(getMsbD, msb)_(extractLsb', extractLsb), getMsbD_extractLsb'_eq_getLsbD.* #6795 adds theorems BitVec.(getElem_umod_of_lt, getElem_umod, getLsbD_umod, getMsbD_umod). For the defiition of these theorems we\nrely on divRec, excluding the case where d=0#w, which is treated\nseparately because there is no infrastructure to reason about this case\nwithin divRec. In particular, our implementation follows the mathlib\nstandard where division by 0 yields\n0,\nwhile in SMTLIB this yields\nallOnes.* #6830 improves some files separation and standardize error messages in\nUV modules* #6850 adds some lemmas about the new tree map. These lemmas are about\nthe interactions of empty, isEmpty, insert, contains. Some\nlemmas about the interaction of contains with the others will follow\nin a later PR.* #6866 adds missing Hashable instances for PUnit and PEmpty.* #6914 introduces ordered map data structures, namely DTreeMap,\nTreeMap, TreeSet and their .Raw variants, into the standard\nlibrary. There are still some operations missing that the hash map has.\nAs of now, the operations are unverified, but the corresponding lemmas\nwill follow in subsequent PRs. While the tree map has already been\noptimized, more micro-optimization will follow as soon as the new code\ngenerator is ready.* #6922 adds LawfulBEq instances for Array and Vector.* #6948 completes the alignment of List/Array/Vectors lemmas for\ninsertIdx.* #6954 verifies the toListfunction for hash maps and dependent hash\nmaps.* #6958 improves the Promise API by considering how dropped promises\ncan lead to never-finished tasks.* #6966 adds an internal-use-only strict linter for the variable names\nof List/Array/Vector variables, and begins cleaning up.* #6982 improves some lemmas about monads and monadic operations on\nArray/Vector, using @Rob23oa's work in\nhttps://github.com/leanprover-community/batteries/pull/1109, and\nadding/generalizing some additional lemmas.* #7013 makes improvements to the simp set for List/Array/Vector/Option\nto improve confluence, in preparation for simp_lc.* #7017 renames the simp set boolToPropSimps to bool_to_prop and\nbv_toNat to bitvec_to_nat. I'll be adding more similarly named simp\nsets.* #7034 adds wf_preprocess theorems for\n{List,Array}.{foldlM,foldrM,mapM,filterMapM,flatMapM}* #7036 adds some deprecated function aliases to the tree map in order\nto ease the transition from the RBMap to the tree map.* #7046 renames UIntX.mk to UIntX.ofBitVec and adds deprecations.* #7048 adds the functions IntX.ofBitVec.* #7050 renames the functions UIntX.val to UIntX.toFin.* #7051 implements the methods insertMany, ofList, ofArray,\nfoldr and foldrM on the tree map.* #7056 adds the UIntX.ofFin conversion functions.* #7057 adds the function UIntX.ofNatLT. This is supposed to be a\nreplacement for UIntX.ofNatCore and UIntX.ofNat', but for\nbootstrapping reasons we need this function to exist in stage0 before we\ncan proceed with the renaming and deprecations, so this PR just adds the\nfunction.* #7059 moves away from using List.get / List.get? / List.get! and\nArray.get!, in favour of using the GetElem mediated getters. In\nparticular it deprecates List.get?, List.get! and Array.get?. Also\nadds Array.back, taking a proof, matching List.getLast.* #7062 introduces the functions UIntX.toIntX as the public API to\nobtain the IntX that is 2's complement equivalent to a given UIntX.* #7063 adds ISize.toInt8, ISize.toInt16, Int8.toISize,\nInt16.toISize.* #7064 renames BitVec.ofNatLt to BitVec.ofNatLT and sets up\ndeprecations for the old name.* #7066 renames IntX.toNat to IntX.toNatClampNeg (to reduce\nsurprises) and sets up a deprecation.* #7068 is a follow-up to #7057 and adds a builtin dsimproc for\nUIntX.ofNatLT which it turns out we need in stage0 before we can get\nthe deprecation of UIntX.ofNatCore in favor of UIntX.ofNatLT off the\nground.* #7070 implements the methods min, max, minKey, maxKey,\natIndex, getEntryLE, getKeyLE and consorts on the tree map.* #7071 unifies the existing functions UIntX.ofNatCore and\nUIntX.ofNat' under a new name, UIntX.ofNatLT.* #7079 introduces Fin.toNat as an alias for Fin.val. We add this\nfunction for discoverability and consistency reasons. The normal form\nfor proofs remains Fin.val, and there is a simp lemma rewriting\nFin.toNat to Fin.val.* #7080 adds the functions UIntX.ofNatTruncate (the version for\nUInt32 already exists).* #7081 adds functions IntX.ofIntLE, IntX.ofIntTruncate, which are\nanalogous to the unsigned counterparts UIntX.ofNatLT and\nUInt.ofNatTruncate.* #7083 adds (value-based, not bitfield-based) conversion functions\nbetween Float/Float32 and IntX/UIntX.* #7105 completes aligning Array/Vector.extract lemmas with the lemmas\nfor List.take and List.drop.* #7106 completes the alignment of List/Array/Vector.finRange lemmas.* #7109 implements the getThenInsertIfNew? and partition functions\non the tree map.* #7114 implements the methods values and valuesArray on the tree\nmap.* #7116 implements the getKey functions on the tree map. It also fixes\nthe naming of the entryAtIdx function on the tree set, which should\nhave been called atIdx.* #7118 implements the functions modify and alter on the tree map.* #7128 adds Repr and Hashable instances for IntX.* #7131 adds IntX.abs functions. These are specified by BitVec.abs,\nso they map IntX.minValue to IntX.minValue, similar to Rust's\ni8::abs. In the future we might also have versions which take values\nin UIntX and/or Nat.* #7137 verifies the various fold and for variants for hashmaps.* #7151 fixes a memory leak in IO.FS.createTempFile* #7158 strengthens Int.tdiv_eq_ediv, by dropping an unnecessary\nhypothesis, in preparation for further work on ediv/tdiv/fdiv\nlemmas.* #7161 adds all missing tree map lemmas about the interactions of the\nfunctions empty, isEmpty, contains, size, insert(IfNew) and\nerase.* #7162 splits Int.DivModLemmas into a Bootstrap and Lemmas file,\nwhere it is possible to use omega in Lemmas.* #7163 gives an unconditional theorem expressing Int.tdiv in terms of\nInt.ediv, not just for non-negative arguments.* #7165 provides tree map lemmas about the interaction of\ncontainsThenInsert(IfNew) with contains and insert(IfNew).* #7167 provides tree map lemmas for the interaction of get? with the\nother operations for which lemmas already exist.* #7174 adds the first batch of lemmas about iterated conversions\nbetween finite types starting with something of type UIntX.* #7199 adds theorems comparing Int.ediv with tdiv and fdiv, for\nall signs of arguments. (Previously we just had the statements about the\ncases in which they agree.)* #7201 adds Array/Vector.left/rightpad. These will not receive any\nverification theorems; simp just unfolds them to an ++ operation.* #7205 completes alignment of\nList.getLast/List.getLast!/List.getLast? lemmas with the\ncorresponding lemmas for Array and Vector.* #7206 adds theorem BitVec.toFin_abs, completing the API for\nBitVec.*_abs.* #7207 provides lemmas for the tree map functions get, get! and\ngetD in relation to the other operations for which lemmas already\nexist.* #7208 aligns lemmas for List.dropLast / Array.pop / Vector.pop.* #7210 adds the remaining lemmas about iterated conversions between\nfinite types starting with something of type UIntX.* #7214 adds a ForIn instance for the PersistentHashSet type.* #7221 provides lemmas about the tree map functions getKey?,\ngetKey, getKey!, getKeyD and insertIfNew and their interaction\nwith other functions for which lemmas already exist.* #7222 removes the simp attribute from ReflCmp.compare_self because\nit matches arbitrary function applications. Instead, a new simp lemma\nReflOrd.compare_self is introduced, which only matches applications of\ncompare.* #7229 provides lemmas for the tree map function getThenInsertIfNew?.* #7235 adds Array.replace and Vector.replace, proves the\ncorrespondences with List.replace, and reproduces the basic API. In\norder to do so, it fills in some gaps in the List.findX APIs.* #7237 provides proofs that the raw tree map operations are well-formed\nand refactors the file structure of the tree map, introducing new\nmodules Std.{DTreeMap,TreeMap,TreeSet}.Raw and splittting\nAdditionalOperations into separate files for bundled and raw types.* #7245 adds missing @[specialize] annotations to the alter and\nmodify functions in Std.Data.DHashMap.Internal.AssocList, which are\nused by the corresponding hash map functions.* #7249 completes alignment of theorems about\nList/Array/Vector.any/all.* #7255 fixes the definition of Min (Option α). This is a breaking\nchange. This treats none as the least element,\nso min none x = min x none = none for all x : Option α. Prior to\nnightly-2025-02-27, we instead had min none (some x) = min (some x) none = some x. Also adds basic lemmas relating min, max, ≤ and\n< on Option.* #7259 contains theorems about IntX that are required for bv_decide\nand the IntX simprocs.* #7260 provides lemmas about the tree map functions keys and toList\nand their interactions with other functions for which lemmas already\nexist. Moreover, a bug in foldr (calling foldlM instead of foldrM)\nis fixed.* #7266 begins the alignment of Int.ediv/fdiv/tdiv theorems.* #7268 implements Lean.ToExpr for finite signed integers.* #7271 changes the order of arguments of the folding function expected\nby the tree map's foldr and foldrM functions so that they are\nconsistent with the API of List.* #7273 fixes the statement of a UIntX conversion lemma.* #7277 fixes a bug in Float32.ofInt, which previously returned a\nFloat(64).Compiler* #6928 makes extern decls evaluate as ⊤ rather than the default value\nof ⊥ in the LCNF elimDeadBranches analysis.* #6930 changes the name generation of specialized LCNF decls so they\ndon't strip macro scopes. This avoids name collisions for\nspecializations created in distinct macro scopes. Since the normal\nName.append function checks for the presence of macro scopes, we need to\nuse appendCore.* #6976 extends the behavior of the sync flag for Task.map/bind etc.\nto encompass synchronous execution even when they first have to wait on\ncompletion of the first task, drastically lowering the overhead of such\ntasks. Thus the flag is now equivalent to e.g. .NET's\nTaskContinuationOptions.ExecuteSynchronously.* #7037 relaxes the minimum required glibc version for Lean and Lean\nexecutables to 2.26 on x86-64 Linux* #7041 marks several LCNF-specific environment extensions as having an\nasyncMode of .sync rather than the default of .mainOnly, so they work\ncorrectly even in async contexts.* #7086 makes the arity reduction pass in the new code generator match\nthe old one when it comes to the behavior of decls with no used\nparameters. This is important, because otherwise we might create a\ntop-level decl with no params that contains unreachable code, which\nwould get evaluated unconditionally during initialization. This actually\nhappens when initializing Init.Core built with the new code generator.Pretty Printing* #7074 modifies the signature pretty printer to add hover information\nfor parameters in binders. This makes the binders be consistent with the\nhovers in pi types.Documentation* #6886 adds recommended spellings for many notations defined in Lean\ncore, using the recommended_spelling command from #6869.* #6950 adds a style guide and a naming convention for the standard\nlibrary.* #6962 improves the doc-string for List.toArray.* #6998 modifies the Prop docstring to point out that every\nproposition is propositionally equal to either True or False. This\nwill help point users toward seeing that Prop is like Bool.* #7026 clarifies the styling of do blocks, and enhanes the naming\nconventions with information about the ext and mono name components\nas well as advice about primed names and naming of simp sets.* #7111 extends the standard library style guide with guidance on\nuniverse variables, notations and Unicode usage, and structure\ndefinitions.Server* #6329 enables the language server to present multiple disjoint line\nranges as being worked on. Even before parallelism lands, we make use of\nthis feature to show post-elaboration tasks such as kernel checking on\nthe first line of a declaration to distinguish them from the final\ntactic step.* #6768 adds preliminary support for inlay hints, as well as support for\ninlay hints that denote the auto-implicits of a function. Hovering over\nan auto-implicit displays its type and double-clicking the auto-implicit\ninserts it into the text document.Breaking Change: The semantic highlighting request handler is not a pure\nrequest handler anymore, but a stateful one. Notably, this means that clients\nthat extend the semantic highlighting of the Lean language server with the\nchainLspRequestHandler function must now use the chainStatefulLspRequestHandler\nfunction instead.* #6887 fixes a bug where the goal state selection would sometimes\nselect incomplete incremental snapshots on whitespace, leading to an\nincorrect \"no goals\" response. Fixes #6594, a regression that was\noriginally introduced in 4.11.0 by #4727.* #6959 implements a number of refinements for the auto-implicit inlay\nhints implemented in #6768.\nSpecifically:* In #6768, there was a bug where the inlay hint edit delay could\naccumulate on successive edits, which meant that it could sometimes take\nmuch longer for inlay hints to show up. implements the basic\ninfrastructure for request cancellation and implements request\ncancellation for semantic tokens and inlay hints to resolve the issue.\nWith this edit delay bug fixed, it made more sense to increase the edit\ndelay slightly from 2000ms to 3000ms.* In #6768, we applied the edit delay to every single inlay hint request\nin order to reduce the amount of inlay hint flickering. This meant that\nthe edit delay also had a significant effect on how far inlay hints\nwould lag behind the file progress bar. adjusts the edit delay\nlogic so that it only affects requests sent directly after a\ncorresponding didChange notification. Once the edit delay is used up,\nall further semantic token requests are responded to without delay, so\nthat the only latency that affects how far the inlay hints lag behind\nthe progress bar is how often we emit refresh requests and how long VS\nCode takes to respond to them.* For inlay hints, refresh requests are now emitted 500ms after a\nresponse to an inlay hint request, not 2000ms, which means that after\nthe edit delay, inlay hints should only lag behind the progress bar by\nabout up to 500ms. This is justifiable for inlay hints because the\nresponse should be much smaller than e.g. is the case for semantic\ntokens.* In #6768, 'Restart File' did not prompt a refresh, but it does now.* VS Code does not immediately remove old inlay hints from the document\nwhen they are applied. In #6768, this meant that inlay hints would\nlinger around for a bit once applied. To mitigate this issue, this PR\nadjusts the inlay hint edit delay logic to identify edits sent from the\nclient as being inlay hint applications, and sets the edit delay to 0ms\nfor the inlay hint requests following it. This means that inlay hints\nare now applied immediately.* In #6768, hovering over single-letter auto-implicit inlay hints was a\nbit finicky because VS Code uses the regular cursor icon on inlay hints,\nnot the thin text cursor icon, which means that it is easy to put the\ncursor in the wrong spot. We now add the separation character (  or\n{) preceding an auto-implicit to the hover range as well, which makes\nhovering over inlay hints much smoother.* #6978 fixes a bug where both the inlay hint change invalidation logic\nand the inlay hint edit delay logic were broken in untitled files.\nThanks to @Julian for spotting this!* #7054 adds language server support for request cancellation to the\nfollowing expensive requests: Code actions, auto-completion, document\nsymbols, folding ranges and semantic highlighting. This means that when\nthe client informs the language server that a request is stale (e.g.\nbecause it belongs to a previous state of the document), the language\nserver will now prematurely cancel the computation of the response in\norder to reduce the CPU load for requests that will be discarded by the\nclient anyways.* #7087 ensures that all tasks in the language server either use\ndedicated tasks or reuse an existing thread from the thread pool. This\nensures that elaboration tasks cannot prevent language server tasks from\nbeing scheduled. This is especially important with parallelism right\naround the corner and elaboration becoming more likely to starve the\nlanguage server of computation, which could drive up language server\nlatencies significantly on machines with few cores.* #7112 adds a tooltip describing what the auto-implicit inlay hints\ndenote, as well as auto-implicit inlay hints for instances.* #7134 significantly improves the performance of auto-completion by\noptimizing individual requests by a factor of ~2 and by giving language\nclients like VS Code the opportunity to reuse the state of previous\ncompletion requests, thus greatly reducing the latency for the\nauto-completion list to update when adding more characters to an\nidentifier.* #7143 makes the server consistently not report newlines between trace\nnodes to the info view, enabling it to render them on dedicates lines\nwithout extraneous spacing between them in all circumstances.* #7149 adds a fast path to the inlay hint request that makes it re-use\nalready computed inlay hints from previous requests instead of\nre-computing them. This is necessary because for some reason VS Code\nemits an inlay hint request for every line you scroll, so we need to be\nable to respond to these requests against the same document state\nquickly. Otherwise, every single scrolled line would result in a request\nthat can take a few dozen ms to be responded to in long files, putting\nunnecessary pressure on the CPU.\nIt also filters the result set by the inlay hints that have been\nrequested.* #7153 changes the server to run lake setup-file on Lake\nconfiguration files (e.g., lakefile.lean).* #7175 fixes an Elab.async regression where elaboration tasks are\ncancelled on document edit even though their result may be reused in the\nnew document version, reporting an incomplete result.Lake* #6829 changes the error message for Lake configuration failure to\nreflect that issues do not always arise from an invalid lakefile, but\nsometimes arise from other issues like network errors. The new error\nmessage encompasses all of these possibilities.* #6929 passes the shared library of the previous stage's Lake as a\nplugin to the next stage's Lake in the CMake build. This enables Lake to\nuse its own builtin elaborators / initializers at build time.* #7001 adds support for plugins to Lake. Precompiled modules are now\nloaded as plugins rather than via --load-dynlib.* #7024 documents how to use Elan's + option with lake new|init. It\nalso provides an more informative error message if a + option leaks\ninto Lake (e.g., if a user provides the option to a Lake run without\nElan).* #7157 changes lake setup-file to now use Lake as a plugin for files\nwhich import Lake (or one of its submodules). Thus, the server will now\nload Lake as a plugin when editing a Lake configuration written in Lean.\nThis further enables the use of builtin language extensions in Lake.* #7171 changes the Lake DSL to use builtin elaborators, macros, and\ninitializers.* #7182 makes lake setup-file succeed on an invalid Lean configuration\nfile.* #7209 fixes broken Lake tests on Windows' new MSYS2. As of MSYS2\n0.0.20250221, OSTYPE is now reported as cygwin instead of msys,\nwhich must be accounted for in a few Lake tests.* #7211 changes the job monitor to perform run job computation itself as\na separate job. Now progress will be reported eagerly, even before all\noutstanding jobs have been discovered. Thus, the total job number\nreported can now grow while jobs are still being computed (e.g., the Y\nin [X/Y[ may increase).* #7233 uses the Lake plugin when Lake is built with Lake via\nUSE_LAKE.* #7291 changes the Lake job monitor to display the last (i.e., newest)\nrunning/unfinished job rather than the first. This avoids the monitor\nfocusing too long on any one job (e.g., \"Running job computation\").* #7399 reverts the new builtin initializers, elaborators, and macros in\nLake back to non-builtin.* #7608 removes the use of the Lake plugin in the Lake build and in\nconfiguration files.Other* #7129 optimizes the performance of the unused variables linter in the\ncase of a definition with a huge Expr representation* #7173 introduces a trace node for each deriving handlers invocation\nfor the benefit of trace.profiler* #7184 adds support for LEAN_BACKTRACE on macOS. This previously only\nworked with glibc, but it can not be enabled for all Unix-like systems,\nsince e.g. Musl does not support it.* #7190 makes the stage2 Leanc build use the stage2 oleans rather than\nstage1 oleans. This was happening because Leanc's own OLEAN_OUT is at\nthe build root rather than the lib/lean subdirectory, so when the build\nadded this OLEAN_OUT to LEAN_PATH no oleans were found there and the\nsearch fell back to the stage1 installation location.\n\n","context":"Lean Reference\u0009Release Notes","header":"Lean 4.18.0 (2025-04-02)","id":"/releases/v4.18.0/#release-v4___18___0"}});